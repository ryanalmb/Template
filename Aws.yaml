AWSTemplateFormatVersion: '2010-09-09'
Description: 'Enhanced Multi-Sport AI Prediction Engine with 4-Model Ensemble (TensorFlow, PyTorch, LightGBM, XGBoost), Amazon Bedrock Claude Integration, Multimodal Analysis, and Comprehensive Telegram Bot'

Parameters:
  KaggleAPIKey:
    Type: String
    NoEcho: true
    Description: Kaggle API key for dataset ingestion

  GitHubToken:
    Type: String
    NoEcho: true
    Description: GitHub Personal Access Token for repository access

  TelegramBotToken:
    Type: String
    NoEcho: true
    Description: Telegram Bot API token

  KeyPairName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: EC2 Key Pair for SSH access

  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, staging, prod]
    Description: Deployment environment

  DeployModels:
    Type: String
    Default: 'false'
    AllowedValues: ['true', 'false']
    Description: Whether to deploy SageMaker models (requires model artifacts in S3)

Conditions:
  ShouldDeployModels: !Equals [!Ref DeployModels, 'true']

Resources:

  ### Secrets Manager for API Keys ###
  KaggleAPISecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-kaggle-api-key
      Description: Kaggle API credentials
      SecretString: !Sub |
        {
          "username": "kaggle-user",
          "key": "${KaggleAPIKey}"
        }

  GitHubTokenSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-github-token
      Description: GitHub Personal Access Token
      SecretString: !Sub |
        {
          "token": "${GitHubToken}"
        }

  TelegramBotSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-telegram-bot-token
      Description: Telegram Bot API token
      SecretString: !Sub |
        {
          "token": "${TelegramBotToken}"
        }

  ### S3 Buckets ###
  SportsDatasetBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-datasets-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  ModelArtifactsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-models-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  PredictionResultsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-results-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  ### DynamoDB Tables ###
  UserPreferencesTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub multisport-user-preferences-${Environment}
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: user_id
          AttributeType: S
        - AttributeName: sport
          AttributeType: S
      KeySchema:
        - AttributeName: user_id
          KeyType: HASH
        - AttributeName: sport
          KeyType: RANGE

  PredictionHistoryTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub multisport-prediction-history-${Environment}
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: prediction_id
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: N
      KeySchema:
        - AttributeName: prediction_id
          KeyType: HASH
        - AttributeName: timestamp
          KeyType: RANGE

  ### Enhanced IAM Roles ###
  SageMakerExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub SageMakerExecutionRole-${Environment}-${AWS::AccountId}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      Policies:
        - PolicyName: SageMakerCustomAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                  - s3:GetBucketLocation
                  - s3:DeleteObject
                  - s3:GetBucketVersioning
                Resource:
                  - !GetAtt SportsDatasetBucket.Arn
                  - !Sub "${SportsDatasetBucket.Arn}/*"
                  - !GetAtt ModelArtifactsBucket.Arn
                  - !Sub "${ModelArtifactsBucket.Arn}/*"
                  - !GetAtt PredictionResultsBucket.Arn
                  - !Sub "${PredictionResultsBucket.Arn}/*"
              - Effect: Allow
                Action:
                  - ecr:GetDownloadUrlForLayer
                  - ecr:BatchGetImage
                  - ecr:BatchCheckLayerAvailability
                  - ecr:GetAuthorizationToken
                  - ecr:DescribeRepositories
                  - ecr:DescribeImages
                  - ecr:DescribeImageScanFindings
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                  - logs:GetLogEvents
                Resource: '*'
              - Effect: Allow
                Action:
                  - iam:PassRole
                Resource: !Sub "arn:aws:iam::${AWS::AccountId}:role/*"
                Condition:
                  StringEquals:
                    iam:PassedToService: sagemaker.amazonaws.com

  # Enhanced Lambda Execution Role with proper dependencies and permissions
  LambdaExecutionRoleV2:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub LambdaExecutionRole-${Environment}-${AWS::AccountId}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                  - s3:DeleteObject
                Resource:
                  - !GetAtt SportsDatasetBucket.Arn
                  - !Sub "${SportsDatasetBucket.Arn}/*"
                  - !GetAtt PredictionResultsBucket.Arn
                  - !Sub "${PredictionResultsBucket.Arn}/*"
                  - !GetAtt ModelArtifactsBucket.Arn
                  - !Sub "${ModelArtifactsBucket.Arn}/*"

        - PolicyName: DynamoDBAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:UpdateItem
                  - dynamodb:DeleteItem
                  - dynamodb:Query
                  - dynamodb:Scan
                  - dynamodb:BatchGetItem
                  - dynamodb:BatchWriteItem
                Resource:
                  - !GetAtt UserPreferencesTable.Arn
                  - !GetAtt PredictionHistoryTable.Arn
                  - !Sub "${UserPreferencesTable.Arn}/index/*"
                  - !Sub "${PredictionHistoryTable.Arn}/index/*"

        - PolicyName: SecretsManagerAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                  - secretsmanager:DescribeSecret
                Resource:
                  - !Ref TelegramBotSecret
                  - !Ref KaggleAPISecret
                  - !Ref GitHubTokenSecret

        - PolicyName: BedrockAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                  - bedrock:GetFoundationModel
                  - bedrock:ListFoundationModels
                Resource: '*'

        - PolicyName: SageMakerAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sagemaker:InvokeEndpoint
                  - sagemaker:DescribeEndpoint
                  - sagemaker:DescribeEndpointConfig
                  - sagemaker:DescribeModel
                Resource: 
                  - !Sub "arn:aws:sagemaker:${AWS::Region}:${AWS::AccountId}:endpoint/*"
                  - !Sub "arn:aws:sagemaker:${AWS::Region}:${AWS::AccountId}:endpoint-config/*"
                  - !Sub "arn:aws:sagemaker:${AWS::Region}:${AWS::AccountId}:model/*"

        - PolicyName: CloudWatchLogsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                Resource: '*'

  ### Lambda Functions ###
  TelegramBotLambda:
    Type: AWS::Lambda::Function
    DependsOn: 
      - LambdaExecutionRoleV2
      - TelegramBotSecret
      - UserPreferencesTable
      - PredictionHistoryTable
      - SportsDatasetBucket
      - PredictionResultsBucket
    Properties:
      FunctionName: !Sub TelegramPredictionBot-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRoleV2.Arn
      Handler: lambda_function.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          from datetime import datetime
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              """Telegram Bot Handler with Bedrock Claude Integration"""
              try:
                  logger.info(f"Received event: {json.dumps(event)}")
                  
                  # Initialize clients
                  secrets_client = boto3.client('secretsmanager')
                  bedrock_client = boto3.client('bedrock-runtime')
                  
                  # Get bot token from secrets manager
                  try:
                      bot_secret = secrets_client.get_secret_value(
                          SecretId=f"{os.environ['ENVIRONMENT']}-telegram-bot-token"
                      )
                      bot_token = json.loads(bot_secret['SecretString'])['token']
                  except Exception as e:
                      logger.error(f"Error getting bot token: {str(e)}")
                      return {'statusCode': 500, 'body': json.dumps({'error': 'Token retrieval failed'})}

                  # Handle webhook verification
                  if 'body' not in event:
                      return {'statusCode': 200, 'body': json.dumps({'status': 'webhook verified'})}

                  body = json.loads(event['body'])
                  logger.info(f"Telegram update: {json.dumps(body)}")

                  if 'message' in body:
                      chat_id = body['message']['chat']['id']
                      message_text = body['message'].get('text', '')
                      user_id = str(body['message']['from']['id'])

                      response_text = handle_command(message_text, user_id, chat_id, bedrock_client)
                      send_message(bot_token, chat_id, response_text)

                  return {'statusCode': 200, 'body': json.dumps({'status': 'success'})}

              except Exception as e:
                  logger.error(f"Lambda handler error: {str(e)}")
                  return {'statusCode': 500, 'body': json.dumps({'error': str(e)})}

          def handle_command(message_text, user_id, chat_id, bedrock_client):
              """Handle bot commands with Bedrock Claude analysis"""

              if message_text.startswith('/predict'):
                  return handle_prediction_with_bedrock(message_text, user_id, bedrock_client)
              elif message_text.startswith('/analysis'):
                  return handle_analysis_with_bedrock(message_text, user_id, bedrock_client)
              elif message_text.startswith('/start'):
                  return get_welcome_message()
              else:
                  return "Use /predict [sport] [team1] vs [team2] for predictions or /start for help"

          def handle_prediction_with_bedrock(message_text, user_id, bedrock_client):
              """Generate prediction using ensemble models + Bedrock Claude"""
              try:
                  # Parse prediction request
                  parts = message_text.split()
                  if len(parts) < 5:
                      return "Format: /predict [sport] [team1] vs [team2]"

                  sport = parts[1]
                  teams_text = ' '.join(parts[2:])
                  
                  if ' vs ' not in teams_text.lower():
                      return "Use format: /predict sport Team1 vs Team2"
                  
                  teams = teams_text.split(' vs ')
                  if len(teams) != 2:
                      teams = teams_text.split(' VS ')
                  
                  if len(teams) != 2:
                      return "Use format: Team1 vs Team2"

                  # Get ensemble prediction (simulate for demo)
                  ensemble_result = get_ensemble_prediction(sport, teams[0].strip(), teams[1].strip())

                  # Generate contextual analysis with Bedrock Claude
                  claude_analysis = generate_bedrock_analysis(sport, teams, ensemble_result, bedrock_client)

                  return f"ðŸ† {sport.upper()} PREDICTION\n\n{teams[0].strip()} vs {teams[1].strip()}\n\n{claude_analysis}"

              except Exception as e:
                  logger.error(f"Prediction error: {str(e)}")
                  return f"Error generating prediction: {str(e)}"

          def generate_bedrock_analysis(sport, teams, prediction_data, bedrock_client):
              """Generate analysis using Amazon Bedrock Claude"""
              try:
                  prompt = f"""Analyze this {sport} match prediction:
          Teams: {teams[0]} vs {teams[1]}
          Model Predictions: Winner - {prediction_data['winner']}, Confidence - {prediction_data['confidence']:.1%}

          Provide a concise analysis covering:
          1. Predicted outcome and confidence level
          2. Key factors that could influence the match
          3. Brief tactical insights

          Keep response under 400 characters for Telegram formatting."""

                  body = {
                      "anthropic_version": "bedrock-2023-05-31",
                      "max_tokens": 250,
                      "messages": [
                          {
                              "role": "user",
                              "content": prompt
                          }
                      ]
                  }

                  response = bedrock_client.invoke_model(
                      modelId='anthropic.claude-3-haiku-20240307-v1:0',
                      body=json.dumps(body)
                  )

                  result = json.loads(response['body'].read())
                  return result['content'][0]['text']

              except Exception as e:
                  logger.error(f"Bedrock error: {str(e)}")
                  return f"Prediction: {prediction_data['winner']} ({prediction_data['confidence']:.1%} confidence)\n\nClaude analysis temporarily unavailable."

          def get_ensemble_prediction(sport, team1, team2):
              """Simulate ensemble model prediction"""
              import random
              winner = random.choice([team1, team2])
              confidence = random.uniform(0.6, 0.9)
              return {
                  'winner': winner,
                  'confidence': confidence,
                  'models': {
                      'tensorflow': confidence + random.uniform(-0.1, 0.1),
                      'pytorch': confidence + random.uniform(-0.1, 0.1),
                      'lightgbm': confidence + random.uniform(-0.1, 0.1),
                      'xgboost': confidence + random.uniform(-0.1, 0.1)
                  }
              }

          def handle_analysis_with_bedrock(message_text, user_id, bedrock_client):
              """Generate detailed match analysis with Bedrock"""
              analysis_query = message_text[10:].strip()
              if not analysis_query:
                  return "Please provide match details after /analysis command"
              
              try:
                  prompt = f"Provide detailed sports analysis for: {analysis_query}. Include tactical insights, key player matchups, and strategic considerations. Keep under 500 characters."

                  body = {
                      "anthropic_version": "bedrock-2023-05-31",
                      "max_tokens": 350,
                      "messages": [{"role": "user", "content": prompt}]
                  }

                  response = bedrock_client.invoke_model(
                      modelId='anthropic.claude-3-haiku-20240307-v1:0',
                      body=json.dumps(body)
                  )

                  result = json.loads(response['body'].read())
                  return result['content'][0]['text']

              except Exception as e:
                  logger.error(f"Analysis error: {str(e)}")
                  return f"Analysis unavailable: {str(e)}"

          def get_welcome_message():
              return """ðŸ† Multi-Sport AI Prediction Bot

          Commands:
          â€¢ /predict [sport] [team1] vs [team2] - AI prediction with Claude analysis
          â€¢ /analysis [match details] - Detailed match analysis

          Example: /predict football Arsenal vs Chelsea

          Powered by 4-model ensemble + Amazon Bedrock Claude ðŸ¤–"""

          def send_message(bot_token, chat_id, text):
              """Send message to Telegram"""
              import urllib3
              
              http = urllib3.PoolManager()
              url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
              
              data = {
                  'chat_id': chat_id,
                  'text': text,
                  'parse_mode': 'HTML'
              }
              
              try:
                  response = http.request('POST', url, fields=data)
                  logger.info(f"Telegram API response: {response.status}")
              except Exception as e:
                  logger.error(f"Send message error: {str(e)}")

      Timeout: 30
      MemorySize: 512
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          DATASET_BUCKET: !Ref SportsDatasetBucket
          RESULTS_BUCKET: !Ref PredictionResultsBucket
          USER_TABLE: !Ref UserPreferencesTable
          HISTORY_TABLE: !Ref PredictionHistoryTable

  ModelEnsembleLambda:
    Type: AWS::Lambda::Function
    DependsOn: 
      - LambdaExecutionRoleV2
      - SportsDatasetBucket
      - ModelArtifactsBucket
    Properties:
      FunctionName: !Sub ModelEnsembleHandler-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRoleV2.Arn
      Handler: lambda_function.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              """Ensemble prediction with Bedrock Claude context generation"""
              try:
                  logger.info(f"Ensemble handler event: {json.dumps(event)}")
                  
                  match_data = event.get('match_data', {})
                  sport = event.get('sport', 'unknown')

                  # Initialize Bedrock client
                  bedrock_client = boto3.client('bedrock-runtime')

                  # Simulate ensemble predictions
                  predictions = simulate_ensemble_predictions(match_data, sport)

                  # Generate Claude context via Bedrock
                  context = generate_bedrock_context(match_data, sport, predictions, bedrock_client)

                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'ensemble_prediction': predictions['ensemble'],
                          'individual_predictions': predictions['individual'],
                          'bedrock_context': context
                      })
                  }

              except Exception as e:
                  logger.error(f"Ensemble handler error: {str(e)}")
                  return {'statusCode': 500, 'body': json.dumps({'error': str(e)})}

          def simulate_ensemble_predictions(match_data, sport):
              """Simulate 4-model ensemble predictions"""
              import random

              base_prob = random.uniform(0.4, 0.8)
              individual = {
                  'tensorflow': max(0.1, min(0.9, base_prob + random.uniform(-0.1, 0.1))),
                  'pytorch': max(0.1, min(0.9, base_prob + random.uniform(-0.1, 0.1))), 
                  'lightgbm': max(0.1, min(0.9, base_prob + random.uniform(-0.1, 0.1))),
                  'xgboost': max(0.1, min(0.9, base_prob + random.uniform(-0.1, 0.1)))
              }

              # Weighted ensemble (TF=0.3, PyTorch=0.3, LightGBM=0.2, XGBoost=0.2)
              ensemble = (individual['tensorflow'] * 0.3 + 
                         individual['pytorch'] * 0.3 +
                         individual['lightgbm'] * 0.2 + 
                         individual['xgboost'] * 0.2)

              return {'individual': individual, 'ensemble': ensemble}

          def generate_bedrock_context(match_data, sport, predictions, bedrock_client):
              """Generate contextual analysis using Bedrock Claude"""
              try:
                  prompt = f"""Generate professional sports analysis context:
          Sport: {sport}
          Match Data: {match_data}  
          Model Predictions - Ensemble: {predictions['ensemble']:.3f}

          Provide insights on prediction confidence, key factors, and analysis summary in under 300 characters."""

                  body = {
                      "anthropic_version": "bedrock-2023-05-31",
                      "max_tokens": 200,
                      "messages": [{"role": "user", "content": prompt}]
                  }

                  response = bedrock_client.invoke_model(
                      modelId='anthropic.claude-3-haiku-20240307-v1:0',
                      body=json.dumps(body)
                  )

                  result = json.loads(response['body'].read())
                  return result['content'][0]['text']

              except Exception as e:
                  logger.error(f"Bedrock context error: {str(e)}")
                  return f"Ensemble confidence: {predictions['ensemble']:.1%}. Context generation temporarily unavailable."

      Timeout: 60
      MemorySize: 1024
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment

  ### SageMaker Endpoints (Conditional) ###
  TensorFlowModel:
    Type: AWS::SageMaker::Model
    Condition: ShouldDeployModels
    Properties:
      ModelName: !Sub tensorflow-sports-model-${Environment}
      ExecutionRoleArn: !GetAtt SageMakerExecutionRole.Arn
      PrimaryContainer:
        Image: 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:2.13-cpu
        ModelDataUrl: !Sub s3://${ModelArtifactsBucket}/tensorflow/model.tar.gz
        Environment:
          SAGEMAKER_PROGRAM: inference.py
          SAGEMAKER_SUBMIT_DIRECTORY: /opt/ml/code

  TensorFlowEndpointConfig:
    Type: AWS::SageMaker::EndpointConfig
    Condition: ShouldDeployModels
    Properties:
      EndpointConfigName: !Sub tensorflow-sports-config-${Environment}
      ProductionVariants:
        - ModelName: !Ref TensorFlowModel
          VariantName: tensorflow-variant
          InitialInstanceCount: 1
          InstanceType: ml.m5.large
          InitialVariantWeight: 1

  TensorFlowModelEndpoint:
    Type: AWS::SageMaker::Endpoint
    Condition: ShouldDeployModels
    Properties:
      EndpointName: !Sub tensorflow-sports-endpoint-${Environment}
      EndpointConfigName: !Ref TensorFlowEndpointConfig

  ### API Gateway ###
  TelegramBotAPI:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub TelegramBotAPI-${Environment}
      Description: API Gateway for Telegram Webhook

  TelegramWebhookResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref TelegramBotAPI
      ParentId: !GetAtt TelegramBotAPI.RootResourceId
      PathPart: telegram

  TelegramWebhookMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TelegramBotAPI
      ResourceId: !Ref TelegramWebhookResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${TelegramBotLambda.Arn}/invocations

  TelegramBotAPIDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: TelegramWebhookMethod
    Properties:
      RestApiId: !Ref TelegramBotAPI
      StageName: !Ref Environment

  ### Lambda Permissions ###
  TelegramBotLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref TelegramBotLambda
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${TelegramBotAPI}/*/*/*

Outputs:
  ### Primary Outputs ###
  TelegramWebhookURL:
    Description: Telegram webhook URL for bot configuration
    Value: !Sub https://${TelegramBotAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/telegram
    Export:
      Name: !Sub ${Environment}-TelegramWebhookURL

  SportsDatasetBucket:
    Description: S3 bucket for sports datasets
    Value: !Ref SportsDatasetBucket
    Export:
      Name: !Sub ${Environment}-SportsDatasetBucket

  ModelArtifactsBucket:
    Description: S3 bucket for model artifacts
    Value: !Ref ModelArtifactsBucket
    Export:
      Name: !Sub ${Environment}-ModelArtifactsBucket

  TensorFlowEndpoint:
    Condition: ShouldDeployModels
    Description: TensorFlow model endpoint
    Value: !Ref TensorFlowModelEndpoint
    Export:
      Name: !Sub ${Environment}-TensorFlowEndpoint

  BedrockIntegration:
    Description: Amazon Bedrock Claude models available
    Value: "anthropic.claude-3-sonnet-20240229-v1:0, anthropic.claude-3-haiku-20240307-v1:0"
    Export:
      Name: !Sub ${Environment}-BedrockModels

  DeploymentInstructions:
    Description: Setup instructions
    Value: !Sub |
      ðŸš€ Multi-Sport AI with Bedrock Claude deployed!

      Setup:
      1. Set Telegram webhook: ${TelegramBotAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/telegram
      2. Upload model artifacts to S3: s3://${ModelArtifactsBucket}/tensorflow/model.tar.gz
      3. Ensure Bedrock access in region ${AWS::Region}
      4. Set DeployModels=true to enable SageMaker endpoints (after uploading models)

      Features: 4-model ensemble + Amazon Bedrock Claude analysis

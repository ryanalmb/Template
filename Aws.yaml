AWSTemplateFormatVersion: '2010-09-09'
Description: 'Enhanced Multi-Sport AI Prediction Engine with 4-Model Ensemble (TensorFlow, PyTorch, LightGBM, XGBoost), Claude API Integration, Multimodal Analysis, and Comprehensive Telegram Bot'

Parameters:
  KaggleAPIKey:
    Type: String
    NoEcho: true
    Description: Kaggle API key for dataset ingestion
    
  GitHubToken:
    Type: String
    NoEcho: true
    Description: GitHub Personal Access Token for repository access
    
  ClaudeAPIKey:
    Type: String
    NoEcho: true
    Description: Anthropic Claude API key for context generation
    
  TelegramBotToken:
    Type: String
    NoEcho: true
    Description: Telegram Bot API token
    
  KeyPairName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: EC2 Key Pair for SSH access
    
  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, staging, prod]
    Description: Deployment environment

Resources:

  ### Secrets Manager for API Keys ###
  KaggleAPISecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-kaggle-api-key
      Description: Kaggle API credentials
      SecretString: !Sub |
        {
          "username": "kaggle-user",
          "key": "${KaggleAPIKey}"
        }

  GitHubTokenSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-github-token
      Description: GitHub Personal Access Token
      SecretString: !Sub |
        {
          "token": "${GitHubToken}"
        }

  ClaudeAPISecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-claude-api-key
      Description: Anthropic Claude API key
      SecretString: !Sub |
        {
          "api_key": "${ClaudeAPIKey}"
        }

  TelegramBotSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub ${Environment}-telegram-bot-token
      Description: Telegram Bot API token
      SecretString: !Sub |
        {
          "token": "${TelegramBotToken}"
        }

  ### S3 Buckets ###
  SportsDatasetBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-datasets-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteIncompleteMultipartUploads
            Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7

  ModelArtifactsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-models-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  PredictionResultsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub multisport-ai-results-${Environment}-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  ### DynamoDB Tables ###
  UserPreferencesTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub multisport-user-preferences-${Environment}
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: user_id
          AttributeType: S
        - AttributeName: sport
          AttributeType: S
      KeySchema:
        - AttributeName: user_id
          KeyType: HASH
        - AttributeName: sport
          KeyType: RANGE
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES

  PredictionHistoryTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub multisport-prediction-history-${Environment}
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: prediction_id
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: N
      KeySchema:
        - AttributeName: prediction_id
          KeyType: HASH
        - AttributeName: timestamp
          KeyType: RANGE
      GlobalSecondaryIndexes:
        - IndexName: timestamp-index
          KeySchema:
            - AttributeName: timestamp
              KeyType: HASH
          Projection:
            ProjectionType: ALL

  ### IAM Roles ###
  SageMakerExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub SageMakerExecutionRole-${Environment}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      Policies:
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !Sub ${SportsDatasetBucket}/*
                  - !GetAtt SportsDatasetBucket.Arn
                  - !Sub ${ModelArtifactsBucket}/*
                  - !GetAtt ModelArtifactsBucket.Arn
        - PolicyName: SecretsManagerPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource:
                  - !Ref KaggleAPISecret
                  - !Ref GitHubTokenSecret
                  - !Ref ClaudeAPISecret

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub LambdaTelegramBotRole-${Environment}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: MultiSportBotPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !Sub ${SportsDatasetBucket}/*
                  - !GetAtt SportsDatasetBucket.Arn
                  - !Sub ${PredictionResultsBucket}/*
                  - !GetAtt PredictionResultsBucket.Arn
              - Effect: Allow
                Action:
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:UpdateItem
                  - dynamodb:Query
                  - dynamodb:Scan
                Resource:
                  - !GetAtt UserPreferencesTable.Arn
                  - !GetAtt PredictionHistoryTable.Arn
                  - !Sub ${UserPreferencesTable.Arn}/index/*
                  - !Sub ${PredictionHistoryTable.Arn}/index/*
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource:
                  - !Ref TelegramBotSecret
                  - !Ref ClaudeAPISecret
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                Resource: '*'
              - Effect: Allow
                Action:
                  - sagemaker:InvokeEndpoint
                Resource: '*'

  EC2Role:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub EC2MultiSportRole-${Environment}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      Policies:
        - PolicyName: SecretsManagerPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource:
                  - !Ref KaggleAPISecret
                  - !Ref GitHubTokenSecret
                  - !Ref ClaudeAPISecret

  ### EC2 Instance Profile ###
  EC2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref EC2Role

  ### Security Groups ###
  EC2SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for Multi-Sport AI EC2 instance
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
          Description: SSH access
        - IpProtocol: tcp
          FromPort: 8888
          ToPort: 8888
          CidrIp: 0.0.0.0/0
          Description: Jupyter Notebook
        - IpProtocol: tcp
          FromPort: 8000
          ToPort: 8010
          CidrIp: 0.0.0.0/0
          Description: Model serving ports

  ### SageMaker Notebook Instance ###
  SageMakerNotebook:
    Type: AWS::SageMaker::NotebookInstance
    Properties:
      InstanceType: ml.t3.xlarge
      RoleArn: !GetAtt SageMakerExecutionRole.Arn
      NotebookInstanceName: !Sub MultiSportNotebook-${Environment}
      DefaultCodeRepository: https://github.com/your-org/multisport-ai-notebooks
      VolumeSizeInGB: 50
      Tags:
        - Key: Project
          Value: MultiSportAI
        - Key: Environment
          Value: !Ref Environment

  ### EC2 Instance for Model Training/Serving ###
  ModelServerEC2:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: g4dn.xlarge
      ImageId: ami-0c55b159cbfafe1f0  # Deep Learning AMI
      KeyName: !Ref KeyPairName
      IamInstanceProfile: !Ref EC2InstanceProfile
      SecurityGroups:
        - !Ref EC2SecurityGroup
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          yum update -y
          yum install -y docker git
          
          # Install Docker Compose
          curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          chmod +x /usr/local/bin/docker-compose
          
          # Start Docker
          service docker start
          usermod -a -G docker ec2-user
          
          # Install Python packages for ensemble models
          pip3 install tensorflow torch lightgbm xgboost scikit-learn pandas numpy matplotlib seaborn plotly anthropic kaggle PyGithub
          
          # Clone model repositories
          cd /home/ec2-user
          git clone https://github.com/your-org/multisport-tensorflow-models.git
          git clone https://github.com/your-org/multisport-pytorch-models.git
          git clone https://github.com/your-org/multisport-lightgbm-models.git
          git clone https://github.com/your-org/multisport-xgboost-models.git
          
          # Set up environment variables
          echo "export KAGGLE_CONFIG_DIR=/home/ec2-user/.kaggle" >> /home/ec2-user/.bashrc
          echo "export GITHUB_TOKEN=${GitHubToken}" >> /home/ec2-user/.bashrc
          echo "export CLAUDE_API_KEY=${ClaudeAPIKey}" >> /home/ec2-user/.bashrc
          
          chown -R ec2-user:ec2-user /home/ec2-user/
      Tags:
        - Key: Name
          Value: !Sub ModelTrainingEC2-${Environment}
        - Key: Project
          Value: MultiSportAI

  ### Lambda Functions ###
  
  # Main Telegram Bot Handler
  TelegramBotLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub TelegramPredictionBot-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRole.Arn
      Handler: telegram_bot.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import requests
          import os
          from datetime import datetime
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              """
              Comprehensive Telegram Bot Handler for Multi-Sport AI Predictions
              Supports commands: /start, /help, /predict, /history, /sports, /analysis, /settings
              """
              try:
                  # Get bot token from Secrets Manager
                  secrets_client = boto3.client('secretsmanager')
                  bot_token = json.loads(
                      secrets_client.get_secret_value(
                          SecretId=f"{os.environ['ENVIRONMENT']}-telegram-bot-token"
                      )['SecretString']
                  )['token']
                  
                  # Parse incoming message
                  body = json.loads(event['body'])
                  
                  if 'message' in body:
                      chat_id = body['message']['chat']['id']
                      message_text = body['message'].get('text', '')
                      user_id = str(body['message']['from']['id'])
                      
                      response_text = handle_command(message_text, user_id, chat_id)
                      
                      # Send response
                      send_message(bot_token, chat_id, response_text)
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({'status': 'success'})
                  }
              
              except Exception as e:
                  logger.error(f"Error processing request: {str(e)}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': str(e)})
                  }

          def handle_command(message_text, user_id, chat_id):
              """Handle different bot commands"""
              
              if message_text.startswith('/start'):
                  return get_welcome_message()
              
              elif message_text.startswith('/help'):
                  return get_help_message()
              
              elif message_text.startswith('/predict'):
                  return handle_prediction_request(message_text, user_id)
              
              elif message_text.startswith('/history'):
                  return get_prediction_history(user_id)
              
              elif message_text.startswith('/sports'):
                  return get_supported_sports()
              
              elif message_text.startswith('/analysis'):
                  return handle_analysis_request(message_text, user_id)
              
              elif message_text.startswith('/settings'):
                  return handle_settings(message_text, user_id)
              
              else:
                  return "I didn't understand that command. Type /help for available commands."

          def get_welcome_message():
              return """
          ðŸ† Welcome to Multi-Sport AI Prediction Bot!

          I can predict outcomes for multiple sports using advanced AI models including:
          â€¢ TensorFlow Neural Networks
          â€¢ PyTorch Deep Learning
          â€¢ LightGBM Gradient Boosting  
          â€¢ XGBoost Ensemble

          Type /help to see all available commands!
          """

          def get_help_message():
              return """
          ðŸ¤– Available Commands:

          /predict [sport] [team1] vs [team2] - Get AI prediction
          /history - View your prediction history
          /sports - List supported sports
          /analysis [match] - Get detailed match analysis with diagrams
          /settings - Configure your preferences

          Examples:
          â€¢ /predict football Liverpool vs Manchester City
          â€¢ /predict basketball Lakers vs Warriors
          â€¢ /analysis Champions League Final 2024
          """

          # Additional handler functions would be implemented here...
          
          def send_message(bot_token, chat_id, text):
              """Send message to Telegram"""
              url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
              payload = {
                  'chat_id': chat_id,
                  'text': text,
                  'parse_mode': 'Markdown'
              }
              requests.post(url, json=payload)
              
      Timeout: 30
      MemorySize: 512
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          DATASET_BUCKET: !Ref SportsDatasetBucket
          RESULTS_BUCKET: !Ref PredictionResultsBucket
          USER_TABLE: !Ref UserPreferencesTable
          HISTORY_TABLE: !Ref PredictionHistoryTable
          REGION: !Ref "AWS::Region"

  # Data Ingestion Lambda
  DataIngestionLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub DataIngestionHandler-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRole.Arn
      Handler: data_ingestion.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import requests
          import os
          from github import Github
          import kaggle

          def lambda_handler(event, context):
              """
              Handle data ingestion from Kaggle and GitHub
              Supports both sports datasets and model repositories
              """
              try:
                  source = event.get('source', 'kaggle')
                  dataset_name = event.get('dataset_name')
                  
                  if source == 'kaggle':
                      return ingest_kaggle_dataset(dataset_name)
                  elif source == 'github':
                      return ingest_github_data(dataset_name)
                  
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': str(e)})
                  }

          def ingest_kaggle_dataset(dataset_name):
              """Download dataset from Kaggle"""
              # Implementation for Kaggle API integration
              pass

          def ingest_github_data(repo_name):
              """Clone/sync GitHub repository data"""
              # Implementation for GitHub API integration
              pass
      Timeout: 300
      MemorySize: 1024
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          DATASET_BUCKET: !Ref SportsDatasetBucket

  # Model Ensemble Lambda
  ModelEnsembleLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ModelEnsembleHandler-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRole.Arn
      Handler: model_ensemble.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import numpy as np
          from typing import Dict, List

          def lambda_handler(event, context):
              """
              Ensemble prediction using 4 models:
              - TensorFlow Neural Network
              - PyTorch Deep Learning
              - LightGBM Gradient Boosting
              - XGBoost Classifier
              """
              try:
                  match_data = event.get('match_data')
                  sport = event.get('sport')
                  
                  # Get predictions from all 4 models
                  tensorflow_pred = get_tensorflow_prediction(match_data, sport)
                  pytorch_pred = get_pytorch_prediction(match_data, sport)
                  lightgbm_pred = get_lightgbm_prediction(match_data, sport)
                  xgboost_pred = get_xgboost_prediction(match_data, sport)
                  
                  # Ensemble prediction with weighted average
                  ensemble_pred = ensemble_predictions([
                      tensorflow_pred, pytorch_pred, lightgbm_pred, xgboost_pred
                  ])
                  
                  # Generate Claude context
                  context = generate_claude_context(match_data, sport, ensemble_pred)
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'ensemble_prediction': ensemble_pred,
                          'individual_predictions': {
                              'tensorflow': tensorflow_pred,
                              'pytorch': pytorch_pred,
                              'lightgbm': lightgbm_pred,
                              'xgboost': xgboost_pred
                          },
                          'context': context
                      })
                  }
              
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': str(e)})
                  }

          def ensemble_predictions(predictions: List[Dict]) -> Dict:
              """Combine predictions using weighted ensemble"""
              # Weights: TensorFlow=0.3, PyTorch=0.3, LightGBM=0.2, XGBoost=0.2
              weights = [0.3, 0.3, 0.2, 0.2]
              
              # Implementation of ensemble logic
              pass

          # Individual model prediction functions
          def get_tensorflow_prediction(match_data, sport):
              # Call TensorFlow model endpoint
              pass

          def get_pytorch_prediction(match_data, sport):
              # Call PyTorch model endpoint
              pass

          def get_lightgbm_prediction(match_data, sport):
              # Call LightGBM model endpoint
              pass

          def get_xgboost_prediction(match_data, sport):
              # Call XGBoost model endpoint
              pass

          def generate_claude_context(match_data, sport, prediction):
              """Generate contextual analysis using Claude API"""
              # Implementation for Claude API integration
              pass
      Timeout: 60
      MemorySize: 1024
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment

  # Multimodal Analysis Lambda
  MultimodalAnalysisLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub MultimodalAnalysisHandler-${Environment}
      Runtime: python3.11
      Role: !GetAtt LambdaExecutionRole.Arn
      Handler: multimodal_analysis.lambda_handler
      Code:
        ZipFile: |
          import json
          import boto3
          import matplotlib.pyplot as plt
          import seaborn as sns
          import plotly.graph_objects as go
          import plotly.express as px
          from io import BytesIO
          import base64

          def lambda_handler(event, context):
              """
              Generate multimodal analysis including:
              - Performance trend charts
              - Head-to-head comparison diagrams
              - Statistical breakdown visualizations
              - Interactive prediction confidence plots
              """
              try:
                  analysis_type = event.get('analysis_type', 'comprehensive')
                  match_data = event.get('match_data')
                  
                  if analysis_type == 'trends':
                      chart = generate_trend_analysis(match_data)
                  elif analysis_type == 'comparison':
                      chart = generate_head_to_head_comparison(match_data)
                  elif analysis_type == 'confidence':
                      chart = generate_confidence_plot(match_data)
                  else:
                      chart = generate_comprehensive_analysis(match_data)
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'chart_data': chart,
                          'analysis_type': analysis_type
                      })
                  }
              
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'body': json.dumps({'error': str(e)})
                  }

          def generate_trend_analysis(match_data):
              """Generate performance trend charts"""
              # Implementation for trend analysis visualization
              pass

          def generate_head_to_head_comparison(match_data):
              """Generate head-to-head comparison diagrams"""
              # Implementation for comparison visualization
              pass

          def generate_confidence_plot(match_data):
              """Generate prediction confidence plots"""
              # Implementation for confidence visualization
              pass

          def generate_comprehensive_analysis(match_data):
              """Generate comprehensive multimodal analysis"""
              # Implementation for comprehensive analysis
              pass
      Timeout: 60
      MemorySize: 1024
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          RESULTS_BUCKET: !Ref PredictionResultsBucket

  ### API Gateway ###
  TelegramBotAPI:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub TelegramBotAPI-${Environment}
      Description: API Gateway for Telegram Webhook and Model Endpoints

  TelegramWebhookResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref TelegramBotAPI
      ParentId: !GetAtt TelegramBotAPI.RootResourceId
      PathPart: telegram

  TelegramWebhookMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TelegramBotAPI
      ResourceId: !Ref TelegramWebhookResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: 
          Fn::Sub: 
            - arn:aws:apigateway:${Region}:lambda:path/2015-03-31/functions/${LambdaArn}/invocations
            - Region: !Ref "AWS::Region"
              LambdaArn: !GetAtt TelegramBotLambda.Arn

  # API Gateway Deployment
  TelegramBotAPIDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: TelegramWebhookMethod
    Properties:
      RestApiId: !Ref TelegramBotAPI
      StageName: !Ref Environment

  ### Lambda Permissions ###
  TelegramBotLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref TelegramBotLambda
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${TelegramBotAPI}/*/*/*

  ### SageMaker Endpoints for Model Ensemble ###
  
  # TensorFlow Model Endpoint
  TensorFlowModelEndpoint:
    Type: AWS::SageMaker::Endpoint
    Properties:
      EndpointName: !Sub tensorflow-sports-model-${Environment}
      EndpointConfigName: !Ref TensorFlowEndpointConfig

  TensorFlowEndpointConfig:
    Type: AWS::SageMaker::EndpointConfig
    Properties:
      EndpointConfigName: !Sub tensorflow-sports-config-${Environment}
      ProductionVariants:
        - ModelName: !Ref TensorFlowModel
          VariantName: tensorflow-variant
          InitialInstanceCount: 1
          InstanceType: ml.t2.medium
          InitialVariantWeight: 1

  TensorFlowModel:
    Type: AWS::SageMaker::Model
    Properties:
      ModelName: !Sub tensorflow-sports-model-${Environment}
      ExecutionRoleArn: !GetAtt SageMakerExecutionRole.Arn
      PrimaryContainer:
        Image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12-cpu
        ModelDataUrl: !Sub s3://${ModelArtifactsBucket}/tensorflow/model.tar.gz

  # PyTorch Model Endpoint
  PyTorchModelEndpoint:
    Type: AWS::SageMaker::Endpoint
    Properties:
      EndpointName: !Sub pytorch-sports-model-${Environment}
      EndpointConfigName: !Ref PyTorchEndpointConfig

  PyTorchEndpointConfig:
    Type: AWS::SageMaker::EndpointConfig
    Properties:
      EndpointConfigName: !Sub pytorch-sports-config-${Environment}
      ProductionVariants:
        - ModelName: !Ref PyTorchModel
          VariantName: pytorch-variant
          InitialInstanceCount: 1
          InstanceType: ml.t2.medium
          InitialVariantWeight: 1

  PyTorchModel:
    Type: AWS::SageMaker::Model
    Properties:
      ModelName: !Sub pytorch-sports-model-${Environment}
      ExecutionRoleArn: !GetAtt SageMakerExecutionRole.Arn
      PrimaryContainer:
        Image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.13-cpu-py39
        ModelDataUrl: !Sub s3://${ModelArtifactsBucket}/pytorch/model.tar.gz

  ### CloudWatch Alarms ###
  HighErrorRateAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub MultiSport-HighErrorRate-${Environment}
      AlarmDescription: Alert when Lambda error rate is high
      MetricName: Errors
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: 10
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref TelegramBotLambda

  ModelEndpointLatencyAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub MultiSport-ModelLatency-${Environment}
      AlarmDescription: Alert when model endpoint latency is high
      MetricName: ModelLatency
      Namespace: AWS/SageMaker
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 5000
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: EndpointName
          Value: !Ref TensorFlowModelEndpoint

  ### SNS Topic for Alerts ###
  AlertsTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub MultiSport-Alerts-${Environment}
      DisplayName: Multi-Sport AI Alerts

  ### EventBridge Rules for Automated Retraining ###
  ModelRetrainingRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub MultiSport-Retraining-${Environment}
      Description: Trigger model retraining weekly
      ScheduleExpression: "rate(7 days)"
      State: ENABLED
      Targets:
        - Arn: !GetAtt DataIngestionLambda.Arn
          Id: DataIngestionTarget
          Input: !Sub |
            {
              "source": "scheduled_retrain",
              "environment": "${Environment}"
            }

  ModelRetrainingPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DataIngestionLambda
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt ModelRetrainingRule.Arn

  ### Step Functions for ML Pipeline ###
  MLPipelineStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub MultiSport-MLPipeline-${Environment}
      RoleArn: !GetAtt StepFunctionsRole.Arn
      DefinitionString: !Sub |
        {
          "Comment": "Multi-Sport AI ML Pipeline",
          "StartAt": "DataIngestion",
          "States": {
            "DataIngestion": {
              "Type": "Task",
              "Resource": "${DataIngestionLambda.Arn}",
              "Next": "ModelTraining"
            },
            "ModelTraining": {
              "Type": "Parallel",
              "Branches": [
                {
                  "StartAt": "TrainTensorFlow",
                  "States": {
                    "TrainTensorFlow": {
                      "Type": "Task",
                      "Resource": "arn:aws:states:::sagemaker:createTrainingJob.sync",
                      "Parameters": {
                        "TrainingJobName.$": "$.tensorflow_job_name",
                        "AlgorithmSpecification": {
                          "TrainingImage": "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12-cpu-py39",
                          "TrainingInputMode": "File"
                        },
                        "RoleArn": "${SageMakerExecutionRole.Arn}",
                        "InputDataConfig": [
                          {
                            "ChannelName": "training",
                            "DataSource": {
                              "S3DataSource": {
                                "S3DataType": "S3Prefix",
                                "S3Uri": "s3://${SportsDatasetBucket}/tensorflow/",
                                "S3DataDistributionType": "FullyReplicated"
                              }
                            }
                          }
                        ],
                        "OutputDataConfig": {
                          "S3OutputPath": "s3://${ModelArtifactsBucket}/tensorflow/"
                        },
                        "ResourceConfig": {
                          "InstanceType": "ml.m5.large",
                          "InstanceCount": 1,
                          "VolumeSizeInGB": 30
                        },
                        "StoppingCondition": {
                          "MaxRuntimeInSeconds": 3600
                        }
                      },
                      "End": true
                    }
                  }
                },
                {
                  "StartAt": "TrainPyTorch",
                  "States": {
                    "TrainPyTorch": {
                      "Type": "Task",
                      "Resource": "arn:aws:states:::sagemaker:createTrainingJob.sync",
                      "Parameters": {
                        "TrainingJobName.$": "$.pytorch_job_name",
                        "AlgorithmSpecification": {
                          "TrainingImage": "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.13-cpu-py39",
                          "TrainingInputMode": "File"
                        },
                        "RoleArn": "${SageMakerExecutionRole.Arn}",
                        "InputDataConfig": [
                          {
                            "ChannelName": "training",
                            "DataSource": {
                              "S3DataSource": {
                                "S3DataType": "S3Prefix",
                                "S3Uri": "s3://${SportsDatasetBucket}/pytorch/",
                                "S3DataDistributionType": "FullyReplicated"
                              }
                            }
                          }
                        ],
                        "OutputDataConfig": {
                          "S3OutputPath": "s3://${ModelArtifactsBucket}/pytorch/"
                        },
                        "ResourceConfig": {
                          "InstanceType": "ml.m5.large",
                          "InstanceCount": 1,
                          "VolumeSizeInGB": 30
                        },
                        "StoppingCondition": {
                          "MaxRuntimeInSeconds": 3600
                        }
                      },
                      "End": true
                    }
                  }
                }
              ],
              "Next": "ModelDeployment"
            },
            "ModelDeployment": {
              "Type": "Task",
              "Resource": "${ModelEnsembleLambda.Arn}",
              "End": true
            }
          }
        }

  StepFunctionsRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub StepFunctionsRole-${Environment}
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: states.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: StepFunctionsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - sagemaker:CreateTrainingJob
                  - sagemaker:DescribeTrainingJob
                  - iam:PassRole
                Resource: '*'

  ### ElastiCache for Model Caching ###
  ModelCacheCluster:
    Type: AWS::ElastiCache::CacheCluster
    Properties:
      CacheNodeType: cache.t3.micro
      Engine: redis
      NumCacheNodes: 1
      ClusterName: !Sub multisport-cache-${Environment}
      VpcSecurityGroupIds:
        - !Ref CacheSecurityGroup

  CacheSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for ElastiCache
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 6379
          ToPort: 6379
          SourceSecurityGroupId: !Ref EC2SecurityGroup

  ### Application Load Balancer for Model Serving ###
  ModelServingALB:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub MultiSport-ALB-${Environment}
      Scheme: internet-facing
      Type: application
      SecurityGroups:
        - !Ref ALBSecurityGroup
      Subnets:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2

  ALBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for Application Load Balancer
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0

  ModelServingTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub MultiSport-TG-${Environment}
      Port: 8000
      Protocol: HTTP
      VpcId: !Ref VPC
      HealthCheckPath: /health
      HealthCheckProtocol: HTTP
      HealthCheckIntervalSeconds: 30
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3

  ModelServingListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref ModelServingTargetGroup
      LoadBalancerArn: !Ref ModelServingALB
      Port: 80
      Protocol: HTTP

  ### VPC Configuration ###
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub MultiSport-VPC-${Environment}

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub MultiSport-PublicSubnet1-${Environment}

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select [1, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub MultiSport-PublicSubnet2-${Environment}

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub MultiSport-IGW-${Environment}

  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway

  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub MultiSport-PublicRT-${Environment}

  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachGateway
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  PublicSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet2
      RouteTableId: !Ref PublicRouteTable

Outputs:
  ### S3 Bucket Outputs ###
  SportsDatasetBucket:
    Description: S3 bucket for storing sports datasets from Kaggle and GitHub
    Value: !Ref SportsDatasetBucket
    Export:
      Name: !Sub ${Environment}-SportsDatasetBucket

  ModelArtifactsBucket:
    Description: S3 bucket for storing trained model artifacts
    Value: !Ref ModelArtifactsBucket
    Export:
      Name: !Sub ${Environment}-ModelArtifactsBucket

  PredictionResultsBucket:
    Description: S3 bucket for storing prediction results and analysis
    Value: !Ref PredictionResultsBucket
    Export:
      Name: !Sub ${Environment}-PredictionResultsBucket

  ### Lambda Function Outputs ###
  TelegramBotFunction:
    Description: Telegram Bot Lambda Function ARN
    Value: !GetAtt TelegramBotLambda.Arn
    Export:
      Name: !Sub ${Environment}-TelegramBotFunction

  DataIngestionFunction:
    Description: Data Ingestion Lambda Function ARN
    Value: !GetAtt DataIngestionLambda.Arn
    Export:
      Name: !Sub ${Environment}-DataIngestionFunction

  ModelEnsembleFunction:
    Description: Model Ensemble Lambda Function ARN
    Value: !GetAtt ModelEnsembleLambda.Arn
    Export:
      Name: !Sub ${Environment}-ModelEnsembleFunction

  MultimodalAnalysisFunction:
    Description: Multimodal Analysis Lambda Function ARN
    Value: !GetAtt MultimodalAnalysisLambda.Arn
    Export:
      Name: !Sub ${Environment}-MultimodalAnalysisFunction

  ### SageMaker Outputs ###
  SageMakerNotebookURL:
    Description: Access URL for SageMaker notebook instance
    Value: !Sub https://${AWS::Region}.console.aws.amazon.com/sagemaker/home?region=${AWS::Region}#/notebook-instances/openNotebook/${SageMakerNotebook}
    Export:
      Name: !Sub ${Environment}-SageMakerNotebookURL

  TensorFlowEndpoint:
    Description: TensorFlow model endpoint name
    Value: !Ref TensorFlowModelEndpoint
    Export:
      Name: !Sub ${Environment}-TensorFlowEndpoint

  PyTorchEndpoint:
    Description: PyTorch model endpoint name
    Value: !Ref PyTorchModelEndpoint
    Export:
      Name: !Sub ${Environment}-PyTorchEndpoint

  ### EC2 Outputs ###
  ModelServerEC2PublicIP:
    Description: Public IP address of the model training/serving EC2 instance
    Value: !GetAtt ModelServerEC2.PublicIp
    Export:
      Name: !Sub ${Environment}-ModelServerEC2PublicIP

  ModelServerEC2InstanceId:
    Description: Instance ID of the model server EC2
    Value: !Ref ModelServerEC2
    Export:
      Name: !Sub ${Environment}-ModelServerEC2InstanceId

  ### API Gateway Outputs ###
  TelegramWebhookURL:
    Description: Telegram webhook URL for bot configuration
    Value: !Sub https://${TelegramBotAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/telegram
    Export:
      Name: !Sub ${Environment}-TelegramWebhookURL

  APIGatewayURL:
    Description: API Gateway base URL
    Value: !Sub https://${TelegramBotAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}
    Export:
      Name: !Sub ${Environment}-APIGatewayURL

  ### DynamoDB Outputs ###
  UserPreferencesTableName:
    Description: DynamoDB table for user preferences
    Value: !Ref UserPreferencesTable
    Export:
      Name: !Sub ${Environment}-UserPreferencesTable

  PredictionHistoryTableName:
    Description: DynamoDB table for prediction history
    Value: !Ref PredictionHistoryTable
    Export:
      Name: !Sub ${Environment}-PredictionHistoryTable

  ### Load Balancer Outputs ###
  ModelServingLoadBalancerDNS:
    Description: DNS name of the model serving load balancer
    Value: !GetAtt ModelServingALB.DNSName
    Export:
      Name: !Sub ${Environment}-ModelServingALB

  ### Step Functions Outputs ###
  MLPipelineStateMachineArn:
    Description: ARN of the ML pipeline state machine
    Value: !Ref MLPipelineStateMachine
    Export:
      Name: !Sub ${Environment}-MLPipelineStateMachine

  ### ElastiCache Outputs ###
  ModelCacheEndpoint:
    Description: ElastiCache Redis endpoint for model caching
    Value: !GetAtt ModelCacheCluster.RedisEndpoint.Address
    Export:
      Name: !Sub ${Environment}-ModelCacheEndpoint

  ### VPC Outputs ###
  VPCId:
    Description: VPC ID for the Multi-Sport AI infrastructure
    Value: !Ref VPC
    Export:
      Name: !Sub ${Environment}-VPC

  PublicSubnet1Id:
    Description: Public Subnet 1 ID
    Value: !Ref PublicSubnet1
    Export:
      Name: !Sub ${Environment}-PublicSubnet1

  PublicSubnet2Id:
    Description: Public Subnet 2 ID
    Value: !Ref PublicSubnet2
    Export:
      Name: !Sub ${Environment}-PublicSubnet2

  ### Usage Instructions ###
  DeploymentInstructions:
    Description: Instructions for using the Multi-Sport AI Prediction Engine
    Value: !Sub |
      ðŸš€ Multi-Sport AI Prediction Engine Deployed Successfully!
      
      ðŸ“‹ Next Steps:
      1. Configure Telegram Bot: Set webhook to ${TelegramBotAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/telegram
      2. Upload model artifacts to S3 buckets
      3. Access SageMaker notebook for development
      4. Connect to EC2 instance for model training: ssh -i ${KeyPairName}.pem ec2-user@${ModelServerEC2.PublicIp}
      5. Monitor CloudWatch alarms and metrics
      
      ðŸ¤– Supported Models: TensorFlow, PyTorch, LightGBM, XGBoost
      ðŸ“Š Features: Multimodal analysis, Claude API integration, comprehensive Telegram bot
      ðŸ”„ Data Sources: Kaggle datasets + GitHub repositories
